# docker-compose from https://developer.confluent.io/quickstart/kafka-docker/

version: '3'
services:

  zookeeper:
    image: confluentinc/cp-zookeeper:6.1.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - instap_net

  broker:
    image: confluentinc/cp-kafka:6.1.1
    container_name: broker
    hostname: broker
    ports:
      - ${BROKER_PORT}:${BROKER_PORT}
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:${BROKER_PORT}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - instap_net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - zookeeper
      - broker
    ports:
      - ${KAFKA_UI_PORT}:${KAFKA_UI_PORT}
    restart: always
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:${BROKER_PORT}
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - instap_net

  init-kafka:
    image: confluentinc/cp-kafka:6.1.1
    depends_on:
      - broker
      - zookeeper
      - kafka-ui
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server broker:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic instap --replication-factor 1 --partitions 1

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server broker:29092 --list
      "
    networks:
      - instap_net

  producer:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: instap_producer
    depends_on:
      logstash:
        condition: service_healthy
    container_name: producer
    env_file:
      - ./producer/credentials.env
    networks:
      - instap_net

  spark:
    build:
      context: spark
    container_name: spark
    networks:
      - instap_net
    depends_on:
      producer:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4g

  logstash:
    build: 
      context: logstash/
      dockerfile: ./Dockerfile
    image: instap_logstash
    container_name: logstash
    ports:
      - "9600:9600"
      - "9700:9700"
    expose:
      - "9600"
      - "9700"
    depends_on: 
      - broker
      - zookeeper
      - kafka-ui
    networks:
      - instap_net
    healthcheck:
      test: "curl -f logstash:9600"
      interval: 5s
      timeout: 5s
      retries: 20

  elasticsearch:
    container_name: elasticsearch
    build:
      context: ./elasticsearch
      dockerfile: Dockerfile
    image: instap_elasticsearch
    networks:
      instap_net:
        ipv4_address: 10.0.100.51
    ports:
        - ${ES_PORT}:${ES_PORT}
    environment:
      cluster.name: ${CLUSTER_NAME}
      node.name: elasticsearch
      discovery.type: single-node
      ES_JAVA_OPTS: -Xms2g -Xmx2g
      xpack.security.enabled: "false"
      xpack.security.enrollment.enabled: "false"
      bootstrap.memory_lock: "true"

  kibana:
    build:
      context: ./kibana
      dockerfile: Dockerfile
    image: instap_kibana
    container_name: kibana
    hostname: kibana
    ports:
      - ${KIBANA_PORT}:${KIBANA_PORT}
    networks:
      instap_net:
        ipv4_address: 10.0.100.52
    environment:
        xpack.security.enabled: "false"
    depends_on:
      - elasticsearch
    volumes:
      - kibanadata:/usr/share/kibana/data

volumes:
  kibanadata:
    driver: local

networks: 
  instap_net:
    name: tap
    driver: bridge
    ipam:
        config:
            - subnet: 10.0.100.1/24
